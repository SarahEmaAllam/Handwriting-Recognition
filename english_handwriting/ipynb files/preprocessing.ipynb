{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a dataset with the images path and the corresponding labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (2.0.1)\r\n",
      "Requirement already satisfied: tensorflow in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (2.13.0rc1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from pandas) (1.24.3)\r\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0-rc1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow) (2.13.0rc1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (23.5.26)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.8.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (16.0.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (23.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.23.1)\r\n",
      "Requirement already satisfied: setuptools in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (67.6.1)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.5.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.15.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.55.0)\r\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0rc0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0rc0)\r\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1rc0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.1rc0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0-rc1->tensorflow) (0.40.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.18.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.30.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.7.0)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.4)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (5.3.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.3.0)\r\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.26.15)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2023.5.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.1.2)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.5.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:31:11.034833Z",
     "start_time": "2023-06-04T23:31:09.879261Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (0.4.0)\r\n",
      "Requirement already satisfied: six in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (1.16.0)\r\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (1.24.3)\r\n",
      "Requirement already satisfied: scipy in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (1.10.1)\r\n",
      "Requirement already satisfied: Pillow in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (9.5.0)\r\n",
      "Requirement already satisfied: matplotlib in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (3.7.1)\r\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (0.20.0)\r\n",
      "Requirement already satisfied: opencv-python in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (4.7.0.72)\r\n",
      "Requirement already satisfied: imageio in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (2.28.1)\r\n",
      "Requirement already satisfied: Shapely in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (2.0.1)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (3.1)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (2023.4.12)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (23.1)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (0.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (1.0.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (4.39.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (1.4.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (2.8.2)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install imgaug"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:31:11.983937Z",
     "start_time": "2023-06-04T23:31:11.036200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Relative path to the dataset\n",
    "iam_lines_path = os.path.join('../IAM-data', 'iam_lines_gt.txt')\n",
    "\n",
    "# Relative path to save the preprocessed data\n",
    "preprocessed_data_path = os.path.join('../IAM-data', 'preprocessed_data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:32:40.620099Z",
     "start_time": "2023-06-04T23:32:40.120747Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_dataframe(iam_lines_path: str):\n",
    "    \"\"\"\n",
    "    Extract the image path and the label from the IAM lines file and\n",
    "    create a pandas dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    iam_lines_path : str\n",
    "        Path to the IAM lines file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        Dataframe containing the image path and the label\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    image_path = None\n",
    "    label = None\n",
    "\n",
    "    # in the file, one line contains the image path, the next line the label, then an empty line\n",
    "    # extract the image path and the label and create a pandas dataframe\n",
    "    with open(iam_lines_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            if not image_path:\n",
    "                image_path = line\n",
    "            else:\n",
    "                label = line\n",
    "        else:\n",
    "            if image_path and label:\n",
    "                data.append((image_path, label))\n",
    "                image_path = None\n",
    "                label = None\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['image_path', 'label'])\n",
    "\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:32:41.158412Z",
     "start_time": "2023-06-04T23:32:41.154188Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       image_path                                            label\n0  a03-017-07.png             into the pro-communist north and the\n1  a03-017-05.png        to 1958 kept the kingdom in peace, though\n2  a03-017-08.png                    pro-western centre and south.\n3  a03-017-02.png     in Phnom Penh indicate that he still regards\n4  a03-017-06.png  at the cost of virtual partition of the country",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a03-017-07.png</td>\n      <td>into the pro-communist north and the</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a03-017-05.png</td>\n      <td>to 1958 kept the kingdom in peace, though</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a03-017-08.png</td>\n      <td>pro-western centre and south.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a03-017-02.png</td>\n      <td>in Phnom Penh indicate that he still regards</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a03-017-06.png</td>\n      <td>at the cost of virtual partition of the country</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_dataframe(iam_lines_path)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:32:42.391391Z",
     "start_time": "2023-06-04T23:32:42.360447Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Crop the images to the specified size\n",
    "- read the images from the specified filepath into a list\n",
    "- crop them to the specified size or the maximum width and height of the images\n",
    "- convert the list to a numpy array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "from typing import List"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:32:44.987102Z",
     "start_time": "2023-06-04T23:32:44.183463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def read_images(filepath: str) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Read the images from the specified filepath\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        Path to the image\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    img : numpy array\n",
    "        Image as a numpy array\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for img in os.listdir(filepath):\n",
    "        try:\n",
    "            img = imageio.imread(os.path.join(filepath, img))\n",
    "            images.append(img)\n",
    "        except:\n",
    "            print('Error reading image: {}'.format(img))\n",
    "            pass\n",
    "\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:32:45.718423Z",
     "start_time": "2023-06-04T23:32:45.709485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(149, 1824)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "images = read_images('IAM-data/img')\n",
    "print(type(images[0]))\n",
    "print(images[0].shape)\n",
    "print(images[0].dtype)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:33:00.856225Z",
     "start_time": "2023-06-04T23:32:47.030549Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum width and height of the images\n",
    "max_shape = np.max([list(img.shape) for img in images], axis=0)\n",
    "\n",
    "print(max_shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:33:00.863506Z",
     "start_time": "2023-06-04T23:33:00.862465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def crop_images(images: List[np.ndarray],\n",
    "                crop_size: tuple[int, int] = None) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Crop the images to the specified size.\n",
    "    They are padded, in order to keep the aspect ratio\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : list\n",
    "        List of images\n",
    "    crop_size : tuple\n",
    "        Size to crop the images to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cropped_images : list\n",
    "        List of cropped images\n",
    "    \"\"\"\n",
    "    # Use the maximum width and height of the images if no crop size is specified\n",
    "    if crop_size is None:\n",
    "        np.max([list(img.shape) for img in images], axis=0)\n",
    "\n",
    "    w = max_shape[0]\n",
    "    h = max_shape[1]\n",
    "    padded_images = []\n",
    "\n",
    "    crop = iaa.Sequential([iaa.PadToFixedSize(\n",
    "        width=w, height=h, position=\"center\", pad_cval=255)])\n",
    "\n",
    "    # Crop the images\n",
    "    for img in images:\n",
    "        padded_img = crop.augment_image(img)\n",
    "        padded_images.append(padded_img)\n",
    "\n",
    "    return padded_images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:33:00.866388Z",
     "start_time": "2023-06-04T23:33:00.862909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crop_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m cropped_images \u001B[38;5;241m=\u001B[39m \u001B[43mcrop_images\u001B[49m(images)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(cropped_images[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'crop_images' is not defined"
     ]
    }
   ],
   "source": [
    "cropped_images = crop_images(images)\n",
    "\n",
    "print(cropped_images[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T23:38:52.700003Z",
     "start_time": "2023-06-04T23:38:52.539837Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def list_to_ndarray(images: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a list of images to a numpy array\n",
    "    Make sure that the images have the same shape (use crop_images)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : list\n",
    "        List of images\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    images : numpy array\n",
    "        Images as a numpy array\n",
    "    \"\"\"\n",
    "    images = np.array(images)\n",
    "\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = list_to_ndarray(cropped_images)\n",
    "\n",
    "print(images.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use Tensorflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T01:02:09.262638Z",
     "start_time": "2023-06-06T01:02:05.722451Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def load_images(img_path: str) -> list[tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Load and decode the images from the specified filepath\n",
    "    :param img_path: str\n",
    "        Path to the images\n",
    "    :return: tf.Tensor\n",
    "        Images as a tf.Tensor list\n",
    "    \"\"\"\n",
    "    images = []\n",
    "\n",
    "    stop = 20\n",
    "    i = 0\n",
    "    for file in os.listdir(img_path):\n",
    "        if i == stop:\n",
    "            break\n",
    "        file_path = os.path.join(img_path, file)\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        images.append(image)\n",
    "        i += 1\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def resize_images(images: list[tf.Tensor],\n",
    "                  size: tuple[int, int] = None) -> list[tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Resize the images to the specified shape\n",
    "    :param size: tuple[int, int]\n",
    "        Size to resize the images to\n",
    "        If None, the image is resized to the original size\n",
    "    :param images: list[tf.Tensor]\n",
    "        List of images as a tf.Tensor\n",
    "    :return: list[tf.Tensor]\n",
    "        Resized images\n",
    "    \"\"\"\n",
    "    # if shape is not specified, use the maximum width and height of the images\n",
    "    if size is None:\n",
    "        size = np.max([list(img.shape) for img in images], axis=0)\n",
    "\n",
    "    (h, w) = (size[0], size[1])\n",
    "\n",
    "    resized_images = []\n",
    "\n",
    "    # resize the images\n",
    "    for img in images:\n",
    "        resized_img = tf.image.resize_with_pad(img, target_height=h, target_width=w)\n",
    "        resized_images.append(resized_img)\n",
    "\n",
    "    return resized_images\n",
    "\n",
    "\n",
    "def load_labels(iam_lines_path: str) -> tuple[list[str], set[str], int]:\n",
    "    \"\"\"\n",
    "    Load the labels from the specified filepath\n",
    "    :param iam_lines_path: str\n",
    "        Path to the labels\n",
    "    :return: tuple[list[str], set[str], int]\n",
    "        List of image names, list labels\n",
    "        Maximum length of the labels\n",
    "    \"\"\"\n",
    "    image_names = []\n",
    "    labels = []\n",
    "    image_path = None\n",
    "    label = None\n",
    "    # vocab = set()\n",
    "    max_label_length = 0\n",
    "\n",
    "    # In the file, one line contains the image path,\n",
    "    # the next line the label, then an empty line.\n",
    "    # Extract the image path and the label and create a pandas dataframe\n",
    "    with open(iam_lines_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    stop = 21\n",
    "    i = 0\n",
    "    for line in lines:\n",
    "        if i == stop:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            if not image_path:\n",
    "                image_path = line\n",
    "            else:\n",
    "                label = line\n",
    "                image_names.append(image_path)\n",
    "                # vocab.update(list(label))\n",
    "                max_label_length = max(max_label_length, len(label))\n",
    "                i += 1\n",
    "        else:\n",
    "            if image_path and label:\n",
    "                labels.append(label)\n",
    "                image_path = None\n",
    "                label = None\n",
    "\n",
    "\n",
    "    # vocab = sorted(vocab)\n",
    "\n",
    "    # return image_names, labels, vocab, max_label_length\n",
    "    return image_names, labels, max_label_length\n",
    "\n",
    "#\n",
    "# def encode_labels(labels: tf.constant, vocab: set[str],\n",
    "#                   max_num_words: int) -> list[list[int]]:\n",
    "#     \"\"\"\n",
    "#     Encode the labels as a tf.Tensor\n",
    "#     :param labels: tf.constant\n",
    "#         List of labels\n",
    "#     :param vocab: set[str]\n",
    "#         Vocabulary of the labels\n",
    "#     :param max_num_words: int\n",
    "#         Maximum number of words in the vocabulary\n",
    "#     :return: list[list[int]]\n",
    "#         Encoded labels as a list\n",
    "#     \"\"\"\n",
    "#     layer = keras.layers.StringLookup(vocabulary=list(vocab))\n",
    "#     encoded_labels = layer(labels)\n",
    "#\n",
    "#     return encoded_labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T01:05:32.931950Z",
     "start_time": "2023-06-06T01:05:32.924221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_tf_dataset(images: list[tf.Tensor], images_names: list[str], labels: list[str])\\\n",
    "        -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Return a tf.data.Dataset object\n",
    "    :param images: list[tf.Tensor]\n",
    "        List of images\n",
    "    :param images_names: list[str]\n",
    "        List of image names\n",
    "    :param labels: list[str]\n",
    "        List of labels\n",
    "    :return: tf.data.Dataset\n",
    "        Dataset object\n",
    "    \"\"\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_labels_tf(labels: list[str], max_len: int) -> tf.constant:\n",
    "    \"\"\"\n",
    "    Get the labels as a tf.constant\n",
    "    :param labels: list[str]\n",
    "        List of labels\n",
    "    :param max_len: int\n",
    "        Maximum label length\n",
    "    :return: tf.constant\n",
    "        Labels as a tf.constant\n",
    "    \"\"\"\n",
    "    # pad the labels to the maximum length\n",
    "    padded_labels = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        labels, maxlen=max_len, padding='post', value=' '\n",
    "    )\n",
    "    data = tf.data.Dataset.from_tensor_slices([[char for char in label] for label in padded_labels])\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T01:02:18.527059Z",
     "start_time": "2023-06-06T01:02:18.495708Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found:  20\n",
      "images resized\n",
      "Number of labels 20\n",
      "vocab:  [' ', '\"', '(', ')', ',', '-', '.', '1', '2', '3', '4', '5', '7', '8', '9', 'A', 'C', 'E', 'F', 'G', 'H', 'L', 'M', 'O', 'P', 'S', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
      "max_label_len:  54\n",
      "vocab size:  49\n"
     ]
    }
   ],
   "source": [
    "image_tensors = load_images('../IAM-data/img')\n",
    "print(\"Number of images found: \", len(image_tensors))\n",
    "image_tensors = resize_images(image_tensors)\n",
    "print(\"images resized\")\n",
    "\n",
    "image_names, labels, vocab, max_label_len = load_labels('../IAM-data/iam_lines_gt.txt')\n",
    "print(\"Number of labels\", len(labels))\n",
    "print(\"vocab: \", vocab)\n",
    "print(\"max_label_len: \", max_label_len)\n",
    "print(\"vocab size: \", len(vocab))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T01:05:34.863816Z",
     "start_time": "2023-06-06T01:05:34.751502Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from keras.src.layers import StringLookup\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Mapping characters to integers.\n",
    "char_to_num = StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "\n",
    "# Mapping integers back to original characters.\n",
    "num_to_char = StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T01:05:50.588637Z",
     "start_time": "2023-06-06T01:05:50.526755Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# encode and pad the labels\n",
    "encoded_labels = char_to_num(tf.strings.unicode_split(labels, input_encoding=\"UTF-8\"))\n",
    "padded_labels = []\n",
    "for label in encoded_labels:\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = max_label_len - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=99)\n",
    "    padded_labels.append(label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T01:05:51.044545Z",
     "start_time": "2023-06-06T01:05:51.026210Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# create a tf.data.Dataset\n",
    "data = tf.data.Dataset.from_tensor_slices((image_tensors, padded_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T01:05:51.871127Z",
     "start_time": "2023-06-06T01:05:51.840101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<_TensorSliceDataset element_spec=(TensorSpec(shape=(224, 2077, 1), dtype=tf.float32, name=None), TensorSpec(shape=(54,), dtype=tf.int64, name=None))>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only 20 samples\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T01:08:36.893368Z",
     "start_time": "2023-06-06T01:08:36.890587Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "- shuffle the data\n",
    "- split the data\n",
    "- data augmentation - make sure not to augment the test data\n",
    "- if imgaug works with tensors - then reuse the code from task 1\n",
    "- create batches\n",
    "- model implementation + architecture (check paper)\n",
    "- optuna implementation\n",
    "- train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])>, <tf.Tensor: shape=(), dtype=string, numpy=b'ana'>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int64, numpy=array([4, 5, 6])>, <tf.Tensor: shape=(), dtype=string, numpy=b'are'>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int64, numpy=array([7, 8, 9])>, <tf.Tensor: shape=(), dtype=string, numpy=b'mere'>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have two lists of ndarrays: list1 and list2\n",
    "list1 = [np.array([1, 2, 3]), np.array([4, 5, 6]), np.array([7, 8, 9])]\n",
    "list2 = [\"ana\", \"are\", \"mere\"]\n",
    "\n",
    "# Convert the lists of ndarrays to a TensorFlow Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((list1, list2))\n",
    "\n",
    "# Iterate over the elements in the dataset\n",
    "for element in dataset:\n",
    "    print(element)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T12:05:37.772516Z",
     "start_time": "2023-06-07T12:05:37.686094Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
