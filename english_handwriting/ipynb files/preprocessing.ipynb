{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (2.0.1)\r\n",
      "Requirement already satisfied: tensorflow in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (2.13.0rc1)\r\n",
      "Requirement already satisfied: numpy in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (1.24.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0-rc1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow) (2.13.0rc1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (23.5.26)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.8.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (16.0.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (23.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.23.1)\r\n",
      "Requirement already satisfied: setuptools in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (67.6.1)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.5.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.15.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.55.0)\r\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0rc0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0rc0)\r\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1rc0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.1rc0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0-rc1->tensorflow) (0.40.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.18.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.30.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.7.0)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.4)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (5.3.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.3.0)\r\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.26.15)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2023.5.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.1.2)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.5.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "! pip install pandas tensorflow tensorflow_datasets numpy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:32.989876Z",
     "start_time": "2023-06-07T23:41:31.770931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (0.4.0)\r\n",
      "Requirement already satisfied: six in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (1.16.0)\r\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (1.24.3)\r\n",
      "Requirement already satisfied: scipy in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (1.10.1)\r\n",
      "Requirement already satisfied: Pillow in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (9.5.0)\r\n",
      "Requirement already satisfied: matplotlib in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (3.7.1)\r\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (0.20.0)\r\n",
      "Requirement already satisfied: opencv-python in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (4.7.0.72)\r\n",
      "Requirement already satisfied: imageio in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (2.28.1)\r\n",
      "Requirement already satisfied: Shapely in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from imgaug) (2.0.1)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (3.1)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (2023.4.12)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (23.1)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (0.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (1.0.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (4.39.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (1.4.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/andreeaioanatudor/Desktop/Uni/Msc/HWR/Handwriting-Recognition/venv/lib/python3.10/site-packages (from matplotlib->imgaug) (2.8.2)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install imgaug"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:33.956194Z",
     "start_time": "2023-06-07T23:41:32.991673Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.src.layers import StringLookup\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:57:45.883722Z",
     "start_time": "2023-06-07T23:57:44.230556Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Relative path to the dataset\n",
    "iam_lines_path = os.path.join('../IAM-data', 'iam_lines_gt.txt')\n",
    "\n",
    "# Relative path to the images\n",
    "img_path = os.path.join('../IAM-data', 'img')\n",
    "\n",
    "# Relative path to save the preprocessed data\n",
    "preprocessed_data_path = os.path.join('../IAM-data', 'preprocessed_data')\n",
    "\n",
    "# parameters\n",
    "max_len = 128\n",
    "padding_token = 99\n",
    "\n",
    "binarize_threshold = 0.7\n",
    "image_size = (64, 512)\n",
    "\n",
    "val_split = 0.2\n",
    "test_split = 0.2\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:37.321998Z",
     "start_time": "2023-06-07T23:41:37.320090Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a dataset with the images path and the corresponding labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_dataframe(iam_lines_path: str):\n",
    "    \"\"\"\n",
    "    Extract the image path and the label from the IAM lines file and\n",
    "    create a pandas dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    iam_lines_path : str\n",
    "        Path to the IAM lines file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        Dataframe containing the image path and the label\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    image_path = None\n",
    "    label = None\n",
    "\n",
    "    # in the file, one line contains the image path, the next line the label, then an empty line\n",
    "    # extract the image path and the label and create a pandas dataframe\n",
    "    with open(iam_lines_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            if not image_path:\n",
    "                image_path = line\n",
    "            else:\n",
    "                label = line\n",
    "        else:\n",
    "            if image_path and label:\n",
    "                data.append((image_path, label))\n",
    "                image_path = None\n",
    "                label = None\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['image_path', 'label'])\n",
    "\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:37.326674Z",
     "start_time": "2023-06-07T23:41:37.325192Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resize the images to the same size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def load_images(images_names: list[str]) -> tuple[list[tf.Tensor], tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Load and decode the images from the specified filepath\n",
    "    :param images_names: list[str]\n",
    "        List of images names\n",
    "    :return: tuple[list[tf.Tensor], tuple[int, int]]\n",
    "        Images as a tf.Tensor list\n",
    "        and the maximum height and width of the images\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    max_h = 0\n",
    "    max_w = 0\n",
    "\n",
    "    for image_file in images_names:\n",
    "        # read the image from the filepath\n",
    "        file_path = os.path.join(img_path, image_file)\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_image(image, channels=1)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "        # binarize the image\n",
    "        image = tf.where(image > binarize_threshold, 1, 0)\n",
    "\n",
    "        # get the maximum height and width\n",
    "        (h, w) = (image.shape[0], image.shape[1])\n",
    "        if h > max_h:\n",
    "            max_h = h\n",
    "        if w > max_w:\n",
    "            max_w = w\n",
    "        images.append(image)\n",
    "\n",
    "    return images, (max_h, max_w)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:37.330170Z",
     "start_time": "2023-06-07T23:41:37.328516Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def resize_images(images: np.ndarray,\n",
    "                  size: tuple[int, int] = image_size) -> list[tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Resize the images to the specified shape\n",
    "    :param size: tuple[int, int]\n",
    "        Size to resize the images to\n",
    "        If None, the image is resized to the original size\n",
    "    :param images: list[tf.Tensor]\n",
    "        List of images as a tf.Tensor\n",
    "    :return: list[tf.Tensor]\n",
    "        Resized images\n",
    "    \"\"\"\n",
    "    # if shape is not specified, use the maximum width and height of the images\n",
    "    if size is None:\n",
    "        size = np.max([list(img.shape) for img in images], axis=0)\n",
    "\n",
    "    (h, w) = (size[0], size[1])\n",
    "\n",
    "    resized_images = []\n",
    "\n",
    "    # resize the images\n",
    "    for img in images:\n",
    "        resized_img = tf.image.resize_with_pad(img, target_height=h, target_width=w)\n",
    "        resized_images.append(resized_img)\n",
    "\n",
    "    return resized_images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:37.333579Z",
     "start_time": "2023-06-07T23:41:37.331663Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode the labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_vocabulary(labels: list[str]) -> tuple[set[str], int]:\n",
    "    \"\"\"\n",
    "    Get the vocabulary from the labels and the maximum label length\n",
    "    :param labels: list[str]\n",
    "        List of labels\n",
    "    :return: tuple[set[str], int]\n",
    "        Vocabulary and maximum label length\n",
    "    \"\"\"\n",
    "\n",
    "    # get the vocabulary and the max len from the training labels\n",
    "    vocab = set()\n",
    "    max_label_len = 0\n",
    "    for label in labels:\n",
    "        vocab.update(label)\n",
    "        if len(label) > max_label_len:\n",
    "            max_label_len = len(label)\n",
    "\n",
    "    vocab = sorted(vocab)\n",
    "\n",
    "    return vocab, max_label_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:37.336544Z",
     "start_time": "2023-06-07T23:41:37.334636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_encoding(vocab: set[str]) -> tuple[StringLookup, StringLookup]:\n",
    "    \"\"\"\n",
    "    Get the encoding and decoding lookup tables\n",
    "    :param vocab: set[str]\n",
    "        Vocabulary\n",
    "    :return: tuple[tf.lookup.StringLookup, tf.lookup.StringLookup]\n",
    "        Encoding and decoding lookup tables\n",
    "    \"\"\"\n",
    "\n",
    "    # Mapping characters to integers.\n",
    "    char_to_num = StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "\n",
    "    # Mapping integers back to original characters.\n",
    "    num_to_char = StringLookup(\n",
    "        vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    "    )\n",
    "\n",
    "    return char_to_num, num_to_char"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:37.339359Z",
     "start_time": "2023-06-07T23:41:37.337593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def encode_labels(labels: list[str], encoder: StringLookup) -> list[tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Encode the labels and pad them to the same length\n",
    "    :param labels: list[str]\n",
    "        List of labels\n",
    "    :param encoder: tf.lookup.StringLookup\n",
    "        Encoder\n",
    "    :return: list[tf.Tensor]\n",
    "        Encoded and padded labels\n",
    "    \"\"\"\n",
    "\n",
    "    padded_labels = []\n",
    "    for label in labels:\n",
    "        encoded_label = encoder(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "        length = tf.shape(encoded_label)[0]\n",
    "        pad_amount = max_label_len - length\n",
    "        encoded_label = tf.pad(encoded_label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "        padded_labels.append(encoded_label)\n",
    "\n",
    "    return padded_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:37.352828Z",
     "start_time": "2023-06-07T23:41:37.340900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df = get_dataframe(iam_lines_path)\n",
    "df.head()\n",
    "\n",
    "# split the dataset into train, validation, test\n",
    "train_df, test_df = train_test_split(df, test_size=test_split, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=val_split, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:37.360014Z",
     "start_time": "2023-06-07T23:41:37.343226Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "          image_path                                              label\n939   g04-007-05.png   as for more secular purposes. In 1910 Dr. Talbot\n187   a03-027-07.png  some 2,000 delegates, the biggest gathering si...\n4050  b01-053-04.png       to optimism is the sign that Germany and the\n4308  e01-062-06.png  to enable the beginner to master all the essen...\n1506  c01-014-00.png  The libretto, by W. H. Auden and Chester Kallman,",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>939</th>\n      <td>g04-007-05.png</td>\n      <td>as for more secular purposes. In 1910 Dr. Talbot</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>a03-027-07.png</td>\n      <td>some 2,000 delegates, the biggest gathering si...</td>\n    </tr>\n    <tr>\n      <th>4050</th>\n      <td>b01-053-04.png</td>\n      <td>to optimism is the sign that Germany and the</td>\n    </tr>\n    <tr>\n      <th>4308</th>\n      <td>e01-062-06.png</td>\n      <td>to enable the beginner to master all the essen...</td>\n    </tr>\n    <tr>\n      <th>1506</th>\n      <td>c01-014-00.png</td>\n      <td>The libretto, by W. H. Auden and Chester Kallman,</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:37.362044Z",
     "start_time": "2023-06-07T23:41:37.355722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# for each split, load and binarize the images,\n",
    "# then resize them to the same size\n",
    "\n",
    "train_imgs, train_shape = load_images(train_df['image_path'].values)\n",
    "val_imgs, test_shape = load_images(val_df['image_path'].values)\n",
    "test_imgs, val_shape = load_images(test_df['image_path'].values)\n",
    "\n",
    "# max_shape = np.max([train_shape, val_shape, test_shape], axis=0)\n",
    "# print(f\"Maximum shape: {max_shape}\")\n",
    "\n",
    "train_imgs = resize_images(train_imgs)\n",
    "val_imgs = resize_images(val_imgs)\n",
    "test_imgs = resize_images(test_imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:54.824314Z",
     "start_time": "2023-06-07T23:41:37.387137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum label length: 128\n",
      "Vocabulary: [' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Vocabulary size: 79\n"
     ]
    }
   ],
   "source": [
    "# get the vocabulary and the maximum label length\n",
    "vocab, max_label_len = get_vocabulary(train_df['label'].values)\n",
    "\n",
    "max_len = max(max_label_len, max_len)\n",
    "\n",
    "print(f\"Maximum label length: {max_len}\")\n",
    "print(f\"Vocabulary: {vocab}\")\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:54.837731Z",
     "start_time": "2023-06-07T23:41:54.822561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# encode the labels\n",
    "encoder, decoder = get_encoding(vocab)\n",
    "encoded_labels = encode_labels(train_df['label'].values, encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:58.640544Z",
     "start_time": "2023-06-07T23:41:54.832641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as for more secular purposes. In 1910 Dr. Talbot\n",
      "tf.Tensor(\n",
      "[54 72  1 59 68 71  1 66 68 71 58  1 72 58 56 74 65 54 71  1 69 74 71 69\n",
      " 68 72 58 72 13  1 36 67  1 16 24 16 15  1 31 71 13  1 47 54 65 55 68 73], shape=(48,), dtype=int64)\n",
      "as for more secular purposes. In 1910 Dr. Talbot\n",
      "\n",
      "some 2,000 delegates, the biggest gathering since 1958\n",
      "tf.Tensor(\n",
      "[72 68 66 58  1 17 11 15 15 15  1 57 58 65 58 60 54 73 58 72 11  1 73 61\n",
      " 58  1 55 62 60 60 58 72 73  1 60 54 73 61 58 71 62 67 60  1 72 62 67 56\n",
      " 58  1 16 24 20 23], shape=(54,), dtype=int64)\n",
      "some 2,000 delegates, the biggest gathering since 1958\n",
      "\n",
      "to optimism is the sign that Germany and the\n",
      "tf.Tensor(\n",
      "[73 68  1 68 69 73 62 66 62 72 66  1 62 72  1 73 61 58  1 72 62 60 67  1\n",
      " 73 61 54 73  1 34 58 71 66 54 67 78  1 54 67 57  1 73 61 58], shape=(44,), dtype=int64)\n",
      "to optimism is the sign that Germany and the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the encoding\n",
    "for label in train_df['label'].values[:3]:\n",
    "    print(label)\n",
    "    encoded = encoder(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    print(encoded)\n",
    "    print(tf.strings.reduce_join(decoder(encoded)).numpy().decode(\"utf-8\"))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:58.650192Z",
     "start_time": "2023-06-07T23:41:58.641286Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# create a tf.data.Dataset\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_imgs, encoded_labels))\n",
    "batches = train_data.batch(batch_size).cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:59.285106Z",
     "start_time": "2023-06-07T23:41:58.662240Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 512, 1)\n",
      "(32, 75)\n",
      "tf.Tensor(\n",
      "[54 72  1 59 68 71  1 66 68 71 58  1 72 58 56 74 65 54 71  1 69 74 71 69\n",
      " 68 72 58 72 13  1 36 67  1 16 24 16 15  1 31 71 13  1 47 54 65 55 68 73\n",
      " 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99\n",
      " 99 99 99], shape=(75,), dtype=int64)\n",
      "as for more secular purposes. In 1910 Dr. Talbot[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 01:41:59.735905: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# check the batches\n",
    "test_batches = batches.take(1).cache()\n",
    "for batch in test_batches:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    print(batch[1][0])\n",
    "    print(tf.strings.reduce_join(decoder(batch[1][0])).numpy().decode(\"utf-8\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:41:59.741902Z",
     "start_time": "2023-06-07T23:41:59.573218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "path = preprocessed_data_path\n",
    "name = \"boo\"\n",
    "data = train_data.take(10)\n",
    "\n",
    "# create dir if it doesn't exist\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "file_path = os.path.join(path, name)\n",
    "data.save(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T00:54:50.527475Z",
     "start_time": "2023-06-08T00:54:50.120224Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 18130869029969417120\n"
     ]
    }
   ],
   "source": [
    "new_data = tf.data.Dataset.load(file_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T01:07:32.989239Z",
     "start_time": "2023-06-08T01:07:32.967779Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(64, 512, 1), dtype=tf.float32, name=None), TensorSpec(shape=(75,), dtype=tf.int64, name=None))\n",
      "(TensorSpec(shape=(64, 512, 1), dtype=tf.float32, name=None), TensorSpec(shape=(75,), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "# show imfo about the dataset\n",
    "print(data.element_spec)\n",
    "print(new_data.element_spec)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T01:07:35.202149Z",
     "start_time": "2023-06-08T01:07:35.197054Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all tensors equal? tf.Tensor(True, shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# check if the datasets are equal\n",
    "\n",
    "# Create an iterator for `data` and `new_data`\n",
    "data_iter = iter(data)\n",
    "new_data_iter = iter(new_data)\n",
    "\n",
    "# Initialize a variable to track the equality of all tensors\n",
    "all_tensors_equal = True\n",
    "\n",
    "# Iterate over the datasets and compare each pair of tensors\n",
    "for data_element, new_data_element in zip(data_iter, new_data_iter):\n",
    "    # Check if the image tensor and label tensor are equal\n",
    "    are_equal = tf.equal(data_element[0], new_data_element[0])\n",
    "    are_equal = tf.reduce_all(are_equal)\n",
    "\n",
    "    # Update the `all_tensors_equal` variable\n",
    "    all_tensors_equal = all_tensors_equal and are_equal\n",
    "\n",
    "    if not all_tensors_equal:\n",
    "        break\n",
    "\n",
    "# Print the final result\n",
    "print(\"Are all tensors equal?\", all_tensors_equal)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T01:10:55.692091Z",
     "start_time": "2023-06-08T01:10:55.666997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([('image', array([b'[[[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n ...\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]]',\n",
      "       b'[[[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n ...\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]\\n\\n [[0.]\\n  [0.]\\n  [0.]\\n  ...\\n  [0.]\\n  [0.]\\n  [0.]]]'],\n",
      "      dtype=object))]), array([b'[62 72  1 62 67  1 54  1 69 74 55  1 76 61 58 71 58  1 73 61 58  1 54 74\\n 73 61 68 71  1 73 61 71 68 76 72  1 54 99 99 99 99 99 99 99 99 99 99 99\\n 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99\\n 99 99 99]',\n",
      "       b'[73 61 58  1 30 68 66 66 68 67 76 58 54 65 73 61  1 45 58 65 54 73 62 68\\n 67 72  1 42 59 59 62 56 58 11  1 46 62 71  1 50 62 65 65 62 54 66 99 99\\n 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99\\n 99 99 99]'],\n",
      "      dtype=object))\n"
     ]
    }
   ],
   "source": [
    "# load the dataframe\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    file_path, batch_size=2, label_name=\"label\")\n",
    "iterator = dataset.as_numpy_iterator()\n",
    "print(next(iterator))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T23:49:01.770969Z",
     "start_time": "2023-06-07T23:49:01.625211Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "decoder_path = os.path.join(preprocessed_data_path, \"decoder.txt\")\n",
    "with open(decoder_path, 'w') as f:\n",
    "    for item in decoder.get_vocabulary():\n",
    "        f.write(\"%s\\n\" % item)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T00:41:33.684237Z",
     "start_time": "2023-06-08T00:41:33.650013Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "- shuffle the data ☑️\n",
    "- split the data ☑️\n",
    "- create batches ☑️\n",
    "- save and load the datasets ☑️\n",
    "- datatype!!!\n",
    "<br>\n",
    "\n",
    "- data augmentation - make sure not to augment the test data\n",
    "- if imgaug works with tensors - then reuse the code from task 1\n",
    "<br>\n",
    "\n",
    "- model implementation + architecture (check paper)\n",
    "- optuna implementation\n",
    "- train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
